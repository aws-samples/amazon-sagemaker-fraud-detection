{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974c37f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nvidia-ml-py3\n",
    "#!yes | pip uninstall torchvision\n",
    "#!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e1a13",
   "metadata": {
    "papermill": {
     "duration": 0.009489,
     "end_time": "2021-06-03T00:10:10.266437",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.256948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PyTorch Batch Inference\n",
    "In this notebook, we'll examine how to do batch transform task with PyTorch in Amazon SageMaker. Throughout the Notebook, terms \"Batch Inference\" and \"Batch Transform\" are used interchangeably.\n",
    "\n",
    "We use an previously built MNIST dataset image classification model. Then, we demonstrate batch transform by using SageMaker Python SDK PyTorch framework. For a more extensive example demonstrating how to build a model as well as how to run batch inference using a manifest file as well as distributed batch inference, please, see the original version of this notebook: \n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_batch_transform/pytorch_mnist_batch_transform/pytorch-mnist-batch-transform.ipynb\n",
    "\n",
    "For batch transform in TensorFlow in Amazon SageMaker, you can follow other Jupyter notebooks [here](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker_batch_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f4902",
   "metadata": {},
   "source": [
    "![inference_overview](notebook_images/inference_overview_image_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfa0dc",
   "metadata": {},
   "source": [
    "![batch_inference_focus](notebook_images/batch_inference_focus_image_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5743e012",
   "metadata": {},
   "source": [
    "![batch_inference](notebook_images/batch_inference_image_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2008ebd",
   "metadata": {
    "papermill": {
     "duration": 0.009319,
     "end_time": "2021-06-03T00:10:10.285106",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.275787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "We'll begin with some necessary imports, and get an Amazon SageMaker session to help perform certain tasks, as well as an IAM role with the necessary permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5e47c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T00:10:10.310480Z",
     "iopub.status.busy": "2021-06-03T00:10:10.309977Z",
     "iopub.status.idle": "2021-06-03T00:10:11.972019Z",
     "shell.execute_reply": "2021-06-03T00:10:11.971547Z"
    },
    "papermill": {
     "duration": 1.677667,
     "end_time": "2021-06-03T00:10:11.972131",
     "exception": false,
     "start_time": "2021-06-03T00:10:10.294464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket:  sagemaker-us-west-2-328296961357\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from shutil import copyfile\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-batch-inference-script\"\n",
    "print(\"Bucket:  {}\".format(bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb78adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncompress 100 MNIST images which we will use for batch inference\n",
    "!tar -xf data/images.tar.gz\n",
    "!mv images/ data/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af1c8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_prefix = \"batch_transform\"\n",
    "local_image_dir = \"data/images\"\n",
    "local_model_dir = \"model\"\n",
    "local_output_path = \"output\"\n",
    "s3_model_location_prefix = os.path.join(prefix, inference_prefix, \"model\")\n",
    "s3_model_location = sagemaker_session.upload_data(path=local_model_dir, bucket=bucket, \n",
    "                        key_prefix=s3_model_location_prefix)\n",
    "s3_model_location = os.path.join(s3_model_location, \"model.tar.gz\")\n",
    "\n",
    "s3_inference_image_location_prefix = os.path.join(prefix, inference_prefix, \"inference_images\")\n",
    "inference_inputs = sagemaker_session.upload_data(\n",
    "                        path=local_image_dir, bucket=bucket, key_prefix=s3_inference_image_location_prefix)\n",
    "\n",
    "s3_prediction_output_prefix = os.path.join(prefix, inference_prefix, \"prediction_output\")\n",
    "s3_prediction_output_path = os.path.join(\"s3://\", bucket, prefix, inference_prefix, \"prediction_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69600c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Create model transformer\n",
    "Now, we will create a transformer object for handling creating and interacting with Amazon SageMaker transform jobs.\n",
    "\n",
    "Here, we implement the `model_fn`, `input_fn`, `predict_fn` and `output_fn` function to override the default [PyTorch inference handler](https://github.com/aws/sagemaker-pytorch-inference-toolkit/blob/master/src/sagemaker_pytorch_serving_container/default_inference_handler.py). \n",
    "\n",
    "It is noted that in `input_fn` function, the inferenced images are encoded as a Python ByteArray. That's why we use `load_from_bytearray` function to load image from `io.BytesIO` then use `PIL.image` to read.\n",
    "\n",
    "```python\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.nn.DataParallel(Net())\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    return model.to(device)\n",
    "\n",
    "    \n",
    "def load_from_bytearray(request_body):\n",
    "    image_as_bytes = io.BytesIO(request_body)\n",
    "    image = Image.open(image_as_bytes)\n",
    "    image_tensor = ToTensor()(image).unsqueeze(0)    \n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    # if set content_type as 'image/jpg' or 'applicaiton/x-npy', \n",
    "    # the input is also a python bytearray\n",
    "    if request_content_type == 'application/x-image': \n",
    "        image_tensor = load_from_bytearray(request_body)\n",
    "    else:\n",
    "        print(\"not support this type yet\")\n",
    "        raise ValueError(\"not support this type yet\")\n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "# Perform prediction on the deserialized object, with the loaded model\n",
    "def predict_fn(input_object, model):\n",
    "    output = model.forward(input_object)\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "    return {'predictions':pred.item()}\n",
    "\n",
    "\n",
    "# Serialize the prediction result into the desired response content type\n",
    "def output_fn(predictions, response_content_type):\n",
    "    return json.dumps(predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f35e49",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating a Transformer object from saved model artifact\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=s3_model_location,\n",
    "    role=role,\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version=\"py3\",\n",
    "    source_dir=\"model-script/\",\n",
    "    entry_point=\"mnist.py\",\n",
    ")\n",
    "\n",
    "# then create transformer from PyTorchModel object\n",
    "transformer = pytorch_model.transformer(instance_count=1, instance_type=\"ml.c5.xlarge\", \n",
    "                                        output_path=s3_prediction_output_path,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb38fa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Running Batch Inference \n",
    "We will use 100 MNIST images for batch inference.\n",
    "The next cell takes ~5 minutes to execute. Most of this time is spent provisioning an EC2 instance and running health checks. The actual inference time for 100 images is less than one minute. You can see it in CloudWatch timestamps.\n",
    "\n",
    "We set `S3DataType=S3Prefix` to use all objects that match the specified S3 key name prefix for batch inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f52a2d6d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................\u001b[34m2022-01-20 00:15:39,886 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 946 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:39,918 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:39,937 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 6d8fe0159cad43a794e98b53c037045b\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:39,947 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:39,967 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,139 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,142 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]42\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,142 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,143 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,163 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,171 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,173 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]44\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,173 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,173 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,173 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,179 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,179 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,180 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,180 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,180 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,183 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,184 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]43\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,184 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,184 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,184 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,222 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,223 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,225 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,227 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,229 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,232 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,235 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,929 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:1642637740\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,931 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.12355041503906|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:1642637740\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,931 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.792362213134766|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:1642637740\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,931 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:13.9|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:1642637740\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,931 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6411.19140625|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:1642637740\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,932 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:935.453125|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:1642637740\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:40,932 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:15.9|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:1642637740\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,285 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 943\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,286 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:1330|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:1642637741\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,287 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:106|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,291 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 965\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,291 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:1333|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:1642637741\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,291 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:88|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,392 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1057\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,393 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1438|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:1642637741\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,393 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:98|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,465 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1105\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,466 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:1513|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:1642637741\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:41,466 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:123|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,483 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:39546 \"GET /ping HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,484 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,513 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:39558 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,514 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,596 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,596 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.56|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:9a64e9da-1ea8-4071-952e-bb1e4d9dd258,timestamp:1642637747\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,597 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,597 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,597 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,597 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,682 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,683 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,684 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,684 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,688 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,696 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.1|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:a5a7c7d0-1c39-4926-b9db-7bcdcde91374,timestamp:1642637747\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,871 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,871 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 11\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,871 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,871 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:9.38|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:e0660c24-d862-44f3-90c1-6ebb1f21060b,timestamp:1642637747\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,871 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:47,872 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,013 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,014 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.09|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:b07ead96-3f13-447a-840a-d9ab4e08b603,timestamp:1642637748\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,014 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,014 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,014 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,015 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,174 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,174 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.9|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:4a012080-9fee-48db-8749-a6100f3d7f1d,timestamp:1642637748\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,175 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,175 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,175 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,176 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,303 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,303 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:88003f2e-7994-4883-b2a6-c2f4375f81b2,timestamp:1642637748\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,303 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,304 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,304 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,304 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,457 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,458 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.78|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:2509a404-ea1d-4cd4-94d9-7dbd52fb5b21,timestamp:1642637748\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,458 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,458 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,458 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,458 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,589 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,589 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:bce41c53-1bd7-44f9-a4b5-308194942082,timestamp:1642637748\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,589 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,590 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,590 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,590 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,878 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,878 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:c4646f9d-36ec-4cc2-b3a0-66afde4ce4e0,timestamp:1642637748\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,879 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,879 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,879 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:48,879 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,081 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,081 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:9436102b-68b4-48e2-9820-f268e75a4083,timestamp:1642637749\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,081 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,081 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,081 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,081 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,173 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,173 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:b58ff011-7ed9-46a3-8c58-04ef7d08452d,timestamp:1642637749\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,174 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,174 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,174 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,174 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,265 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,265 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:81b9b248-9306-4bd2-b52d-cd4d259d1331,timestamp:1642637749\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,266 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,266 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,266 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,266 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,440 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,440 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.88|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8e81c290-a125-498a-9ae8-e194cadb0249,timestamp:1642637749\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,440 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,440 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,440 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,440 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,580 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,580 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.99|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:80b9602e-f9bf-4a2d-8115-6021e7ea02c5,timestamp:1642637749\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,580 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,580 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,580 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,580 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,690 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:b61b9f5f-4e93-4ba0-9864-77c3358dfae3,timestamp:1642637749\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,691 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,691 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,691 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,691 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,692 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,907 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,907 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.6|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:738e468d-f874-4c7c-a3bf-6b2e4c39ff7c,timestamp:1642637749\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,908 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,908 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,908 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:49,908 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,055 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,055 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:1a9907bf-b16d-4823-8082-85f945078625,timestamp:1642637750\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,055 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,055 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,056 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,056 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,186 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.43|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:5f4513a4-2b39-44c9-9c39-793c9b84358e,timestamp:1642637750\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,188 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,188 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,188 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,189 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,189 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,291 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,291 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:43b8708e-f516-4c12-b5a0-ac4ef44c9809,timestamp:1642637750\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,292 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,292 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,292 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,292 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,421 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,421 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:cbb6b93c-eade-481d-9b25-cfaa7a895235,timestamp:1642637750\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,421 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,421 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,421 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,421 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,572 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,572 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.82|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:c87e5dd2-504d-4cee-9b5f-af759a907821,timestamp:1642637750\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,573 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,573 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,573 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,573 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,723 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,724 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,723 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:e7dacfe0-8e13-498c-a994-0a710291e0f6,timestamp:1642637750\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,724 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,724 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,724 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,828 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,828 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,828 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.27|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:9dcefc02-fa48-445d-9e88-ee5558365d5a,timestamp:1642637750\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,828 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,828 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:50,828 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,110 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.78|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:c2cc77da-08e6-45bc-9a10-c5225cd76a98,timestamp:1642637751\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,112 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,112 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,112 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,113 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,113 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,273 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,273 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.69|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:733c1090-f60d-4db4-851b-db3da881f0ff,timestamp:1642637751\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,274 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 6\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,274 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,274 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,275 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,370 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,370 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:55631615-9789-429f-bd81-ea4e72aa739f,timestamp:1642637751\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,370 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,371 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,371 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,371 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,497 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:f4d7cae2-4b5a-4863-a77e-ade594126919,timestamp:1642637751\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,498 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,498 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,498 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,498 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,499 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,734 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,734 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:d6444bfd-aada-4f25-b614-9e596e7e3035,timestamp:1642637751\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,734 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,734 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,735 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,735 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,873 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,873 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.71|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:7dfdbd94-f83f-4ccf-b540-3142bbfea74f,timestamp:1642637751\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,873 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,873 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,874 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,874 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,990 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,990 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:fea985a2-a195-4e2d-8d26-d32af8ffdba1,timestamp:1642637751\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,991 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,991 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,991 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:51,991 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,174 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,174 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.72|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:2f0a3f18-3810-49d8-9f6d-cb8ecb3aae5c,timestamp:1642637752\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,174 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,174 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,175 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,175 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,328 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,328 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:eccbf12c-b569-40b5-b23e-81e9ac7e738f,timestamp:1642637752\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,328 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,328 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,328 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,329 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-01-20T00:15:47.529:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,612 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,612 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:01ab99cb-297e-406e-9b8b-9e89c0810696,timestamp:1642637752\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,613 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,613 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,613 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,613 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,612 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,612 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:01ab99cb-297e-406e-9b8b-9e89c0810696,timestamp:1642637752\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,613 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,613 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,613 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,613 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,729 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ec5e56a4-f75b-47f7-81b7-69e74fd4db89,timestamp:1642637752\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,732 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,732 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,732 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,733 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,733 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,852 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:cf5a6422-0280-4a7d-9445-dd9a328a17fe,timestamp:1642637752\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,852 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,853 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,853 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,853 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:52,853 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,022 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:771e5ccb-560b-4620-9212-fb2fe8f0a00a,timestamp:1642637753\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,023 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,023 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,023 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,023 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,023 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,292 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,292 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.48|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:d7d00ff1-c271-49ea-8a73-c1442c3d855d,timestamp:1642637753\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,292 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,292 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,293 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,293 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,729 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ec5e56a4-f75b-47f7-81b7-69e74fd4db89,timestamp:1642637752\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,732 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,732 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,732 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,733 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,733 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,852 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.42|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:cf5a6422-0280-4a7d-9445-dd9a328a17fe,timestamp:1642637752\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,852 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,853 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,853 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,853 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:52,853 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,022 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:771e5ccb-560b-4620-9212-fb2fe8f0a00a,timestamp:1642637753\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,023 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,023 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,023 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,023 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,023 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,292 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,292 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.48|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:d7d00ff1-c271-49ea-8a73-c1442c3d855d,timestamp:1642637753\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,292 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,292 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,293 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,293 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.52|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:6f651b18-1a2d-46fd-be0b-8353068c7c42,timestamp:1642637753\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,661 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,661 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.54|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:4fdc3bc6-1ae5-4ce1-a75c-73ad1be689f1,timestamp:1642637753\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,662 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,662 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,662 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,662 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.52|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:6f651b18-1a2d-46fd-be0b-8353068c7c42,timestamp:1642637753\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,570 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,661 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,661 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.54|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:4fdc3bc6-1ae5-4ce1-a75c-73ad1be689f1,timestamp:1642637753\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,662 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,662 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,662 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,662 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:17af1768-5232-4a07-8a9d-a7df962cf802,timestamp:1642637753\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,905 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,905 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:3bcf04d0-fe56-4f7c-ac6d-d583e9abd0cb,timestamp:1642637753\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,905 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,906 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,906 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:53,906 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,000 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,001 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ae2dbcda-85e7-4e6c-9e14-149662075e98,timestamp:1642637754\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,001 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,001 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,001 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,001 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,110 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,110 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,110 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,110 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8baa88ed-6cca-4bb1-ad12-1b5ecebdc0af,timestamp:1642637754\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,111 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,111 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,253 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,253 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8e51018d-9e21-4c4d-8afd-c5ffcc8db9b5,timestamp:1642637754\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,253 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,253 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,254 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,254 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:17af1768-5232-4a07-8a9d-a7df962cf802,timestamp:1642637753\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,817 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,905 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,905 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:3bcf04d0-fe56-4f7c-ac6d-d583e9abd0cb,timestamp:1642637753\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,905 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,906 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,906 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:53,906 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,000 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,001 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ae2dbcda-85e7-4e6c-9e14-149662075e98,timestamp:1642637754\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,001 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,001 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,001 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,001 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,110 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,110 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,110 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,110 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8baa88ed-6cca-4bb1-ad12-1b5ecebdc0af,timestamp:1642637754\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,111 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,111 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,253 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,253 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8e51018d-9e21-4c4d-8afd-c5ffcc8db9b5,timestamp:1642637754\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,253 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,253 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,254 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,254 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,383 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,383 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,383 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.54|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8ecc99fc-c33d-4ad5-b204-bf5156aba209,timestamp:1642637754\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,383 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,383 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,383 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,384 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,492 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,492 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:b6224656-952e-4687-acec-92016bb1d6de,timestamp:1642637754\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,492 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,492 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,492 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,493 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:7d523186-01ce-43a3-8817-a482cb76f40c,timestamp:1642637754\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,698 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,698 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:7636f379-135a-4237-bc00-02fe317bf581,timestamp:1642637754\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,699 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,699 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,699 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,699 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,815 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,815 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:70c1ded3-b4e2-4dad-872a-40bc3be17a14,timestamp:1642637754\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,815 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,815 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,816 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,816 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,919 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,919 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:d119f1d3-ba16-4f4b-a525-e29c2f773fb1,timestamp:1642637754\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,920 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,920 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,920 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:54,920 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,033 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,034 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:992378dd-5b39-41e0-9357-5f0407facf86,timestamp:1642637755\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,034 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,034 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,034 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,034 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,212 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,212 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:49094000-260e-4b9e-b9c5-68f128f120ff,timestamp:1642637755\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,212 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,212 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,212 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,213 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,383 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.54|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8ecc99fc-c33d-4ad5-b204-bf5156aba209,timestamp:1642637754\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,383 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,383 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,383 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,384 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,492 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,492 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:b6224656-952e-4687-acec-92016bb1d6de,timestamp:1642637754\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,492 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,492 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,492 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,493 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:7d523186-01ce-43a3-8817-a482cb76f40c,timestamp:1642637754\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,607 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,698 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,698 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:7636f379-135a-4237-bc00-02fe317bf581,timestamp:1642637754\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,699 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,699 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,699 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,699 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,815 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,815 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.53|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:70c1ded3-b4e2-4dad-872a-40bc3be17a14,timestamp:1642637754\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,815 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,815 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,816 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,816 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,919 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,919 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:d119f1d3-ba16-4f4b-a525-e29c2f773fb1,timestamp:1642637754\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,920 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,920 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,920 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:54,920 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,033 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,034 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:992378dd-5b39-41e0-9357-5f0407facf86,timestamp:1642637755\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,034 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,034 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,034 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,034 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,212 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,212 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:49094000-260e-4b9e-b9c5-68f128f120ff,timestamp:1642637755\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,212 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,212 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,212 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,213 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:47f4adc6-76e1-4c1d-9eeb-3152680f6e07,timestamp:1642637755\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,507 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,507 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:c1a71dcf-db86-4a0d-890d-db505b443dc5,timestamp:1642637755\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,507 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,507 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,507 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,508 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,613 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ddfacd10-c837-4eab-a0d9-7ce405c26954,timestamp:1642637755\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,613 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,613 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,613 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,613 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,614 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:c1d33a2c-040c-40fe-811e-e0f857b5cb5f,timestamp:1642637755\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,866 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,867 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,866 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:45af9190-a3a8-41e0-85f7-ff515fef2c96,timestamp:1642637755\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,867 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,868 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:55,868 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,068 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,068 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:0cee2d98-0f24-48b1-9997-77edbf90c5f4,timestamp:1642637756\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,068 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,068 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,069 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,069 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.43|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:02344bd4-6d93-48e9-8081-b7b364c54492,timestamp:1642637756\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,350 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:0fc5747b-df21-4236-8f65-b73acf9069cb,timestamp:1642637756\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,350 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,351 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,351 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,351 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:47f4adc6-76e1-4c1d-9eeb-3152680f6e07,timestamp:1642637755\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,399 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,507 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,507 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:c1a71dcf-db86-4a0d-890d-db505b443dc5,timestamp:1642637755\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,507 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,507 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,507 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,508 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,613 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ddfacd10-c837-4eab-a0d9-7ce405c26954,timestamp:1642637755\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,613 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,613 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,613 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,613 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,614 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:c1d33a2c-040c-40fe-811e-e0f857b5cb5f,timestamp:1642637755\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,761 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,866 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,867 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,866 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:45af9190-a3a8-41e0-85f7-ff515fef2c96,timestamp:1642637755\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,867 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,868 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:55,868 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,068 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,068 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:0cee2d98-0f24-48b1-9997-77edbf90c5f4,timestamp:1642637756\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,068 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,068 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,069 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,069 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.43|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:02344bd4-6d93-48e9-8081-b7b364c54492,timestamp:1642637756\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,181 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,350 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:0fc5747b-df21-4236-8f65-b73acf9069cb,timestamp:1642637756\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,350 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,351 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,351 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,351 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,351 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,351 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:3f0f63b9-a02f-4802-9ef3-e413abec8f97,timestamp:1642637756\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,558 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:d166fc59-893d-4365-8d7f-b72f48c100f3,timestamp:1642637756\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,559 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,559 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,559 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,559 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,559 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:fe78d001-8d0d-4d32-9bdc-7004a607640b,timestamp:1642637756\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,796 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,796 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ee8b3c85-08a7-41d6-a1f8-675dab74782d,timestamp:1642637756\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,796 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,796 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,797 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,797 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:3c860ee0-b4a9-4799-bc2c-8a0e95c53f6e,timestamp:1642637756\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:63d37468-c2cf-422b-bbc4-d0242ca3f87e,timestamp:1642637757\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,224 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 7\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:3f0f63b9-a02f-4802-9ef3-e413abec8f97,timestamp:1642637756\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,463 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,558 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:d166fc59-893d-4365-8d7f-b72f48c100f3,timestamp:1642637756\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,559 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,559 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,559 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,559 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,559 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.59|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:fe78d001-8d0d-4d32-9bdc-7004a607640b,timestamp:1642637756\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,719 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,796 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,796 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.38|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ee8b3c85-08a7-41d6-a1f8-675dab74782d,timestamp:1642637756\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,796 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,796 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,797 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,797 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.4|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:3c860ee0-b4a9-4799-bc2c-8a0e95c53f6e,timestamp:1642637756\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:56,944 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:63d37468-c2cf-422b-bbc4-d0242ca3f87e,timestamp:1642637757\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,094 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,224 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,224 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:fb8ec913-a554-45cd-a5d9-9a34ad090a93,timestamp:1642637757\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,224 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,224 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,225 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,225 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,367 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,367 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:d3b36e81-9fce-46b1-8634-172d8cf3820e,timestamp:1642637757\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,368 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,368 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,368 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,368 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,224 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:fb8ec913-a554-45cd-a5d9-9a34ad090a93,timestamp:1642637757\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,224 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,224 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,225 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,225 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,367 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,367 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.81|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:d3b36e81-9fce-46b1-8634-172d8cf3820e,timestamp:1642637757\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,368 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,368 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,368 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,368 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:6afe89b3-0c37-487f-b2ac-a4a7a2c49ede,timestamp:1642637757\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:4e69e7f6-166b-4203-a919-b5a37eea7523,timestamp:1642637757\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:886dfe24-fdd5-4a83-84f2-2bb091e8771f,timestamp:1642637757\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:6afe89b3-0c37-487f-b2ac-a4a7a2c49ede,timestamp:1642637757\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,605 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.33|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:4e69e7f6-166b-4203-a919-b5a37eea7523,timestamp:1642637757\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,713 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:886dfe24-fdd5-4a83-84f2-2bb091e8771f,timestamp:1642637757\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,843 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:09a3bc01-9608-432e-a8cf-6147328dfb63,timestamp:1642637757\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8bbeb2ad-c6e3-425c-a581-40d5e5dfe116,timestamp:1642637758\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:2de0ac61-c1cb-4129-87b1-38ca7f067f23,timestamp:1642637758\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,356 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,356 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:1d5ced68-1ecc-4923-8090-bfb52b7805f0,timestamp:1642637758\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,356 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,356 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,356 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,357 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.32|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:09a3bc01-9608-432e-a8cf-6147328dfb63,timestamp:1642637757\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:57,980 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8bbeb2ad-c6e3-425c-a581-40d5e5dfe116,timestamp:1642637758\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,129 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:2de0ac61-c1cb-4129-87b1-38ca7f067f23,timestamp:1642637758\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,356 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,356 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:1d5ced68-1ecc-4923-8090-bfb52b7805f0,timestamp:1642637758\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,356 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,356 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,356 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,357 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8ec12461-155b-4b95-be54-5d503444c7d0,timestamp:1642637758\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,650 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,650 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:5973ef1d-d3a4-48db-ad08-891c2940ee40,timestamp:1642637758\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,651 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,651 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,651 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8ec12461-155b-4b95-be54-5d503444c7d0,timestamp:1642637758\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,525 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,650 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,650 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:5973ef1d-d3a4-48db-ad08-891c2940ee40,timestamp:1642637758\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,651 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,651 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,651 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,651 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:552947b4-008f-422f-a388-34ed4f15269a,timestamp:1642637758\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:12fc3ef5-fe8d-42b6-b8f8-2479ec47406e,timestamp:1642637758\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.62|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:73f3501b-0eaf-4c02-b6d0-1257c1b92c58,timestamp:1642637758\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,072 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,073 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:b89fdcad-5a0a-4e90-ab7b-8eda93f2e93e,timestamp:1642637759\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,073 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,073 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,073 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,073 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,196 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,196 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:7abd07dc-c842-4dbf-927f-3c3aef4f3209,timestamp:1642637759\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,196 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,196 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,196 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,197 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,276 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,276 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,277 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,277 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,277 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,276 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:d9460878-3d6a-48d7-89d6-76c29ee97939,timestamp:1642637759\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,651 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.5|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:552947b4-008f-422f-a388-34ed4f15269a,timestamp:1642637758\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,733 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.3|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:12fc3ef5-fe8d-42b6-b8f8-2479ec47406e,timestamp:1642637758\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,867 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.62|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:73f3501b-0eaf-4c02-b6d0-1257c1b92c58,timestamp:1642637758\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:58,987 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,072 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,073 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:b89fdcad-5a0a-4e90-ab7b-8eda93f2e93e,timestamp:1642637759\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,073 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,073 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,073 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,073 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,196 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,196 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:7abd07dc-c842-4dbf-927f-3c3aef4f3209,timestamp:1642637759\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,196 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 5\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,196 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,196 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,197 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,276 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,276 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,277 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,277 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,277 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,276 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.65|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:d9460878-3d6a-48d7-89d6-76c29ee97939,timestamp:1642637759\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,414 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,414 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,414 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.88|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:950d3997-3a95-4df2-b681-f87328cc6762,timestamp:1642637759\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,414 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,414 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,415 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,415 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,537 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,537 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:446255ad-90c5-4788-97f5-0ff2469540f2,timestamp:1642637759\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,538 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,538 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,538 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,538 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,658 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,659 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,659 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.8|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:f2ff5764-0c6f-4399-add2-4050271d1595,timestamp:1642637759\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,659 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,659 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,659 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,803 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,803 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:219810fc-7d05-44a3-9c95-40c647d709e8,timestamp:1642637759\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,804 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,804 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,804 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,804 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,899 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,899 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ee418ec0-85ec-4b9a-961f-f14d7e03bc41,timestamp:1642637759\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,899 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,899 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,900 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:15:59,900 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:06a12d38-02a7-4052-b3d3-4e02ade5e360,timestamp:1642637760\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.93|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:e8e2ec0c-6432-457d-9ba6-aa84a24839ba,timestamp:1642637760\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,208 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,208 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,414 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.88|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:950d3997-3a95-4df2-b681-f87328cc6762,timestamp:1642637759\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,414 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,414 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,415 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,415 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,537 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,537 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.76|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:446255ad-90c5-4788-97f5-0ff2469540f2,timestamp:1642637759\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,538 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,538 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,538 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,538 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,658 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,659 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,659 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.8|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:f2ff5764-0c6f-4399-add2-4050271d1595,timestamp:1642637759\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,659 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,659 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,659 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,803 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,803 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:219810fc-7d05-44a3-9c95-40c647d709e8,timestamp:1642637759\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,804 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,804 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,804 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,804 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,899 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,899 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ee418ec0-85ec-4b9a-961f-f14d7e03bc41,timestamp:1642637759\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,899 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,899 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,900 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:15:59,900 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:06a12d38-02a7-4052-b3d3-4e02ade5e360,timestamp:1642637760\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,011 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.93|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:e8e2ec0c-6432-457d-9ba6-aa84a24839ba,timestamp:1642637760\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,133 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,208 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,208 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,208 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:49e516e7-0c42-44c2-918f-bf092583944a,timestamp:1642637760\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,209 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,209 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,209 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,342 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,342 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:146fb860-8e09-4c4c-8d76-8cbc4c7891c2,timestamp:1642637760\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,342 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,342 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,343 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,343 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,208 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.46|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:49e516e7-0c42-44c2-918f-bf092583944a,timestamp:1642637760\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,209 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,209 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,209 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,342 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,342 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:146fb860-8e09-4c4c-8d76-8cbc4c7891c2,timestamp:1642637760\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,342 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,342 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,343 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,343 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:0c7254ee-afee-46d9-8af6-f5d6d78cd927,timestamp:1642637760\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,634 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.74|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:dbe8a6c3-cf93-448a-b01a-6f22cd071f6f,timestamp:1642637760\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,635 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,635 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,635 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,636 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,636 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ba94e425-70d3-4873-80e0-6ca0026d5bce,timestamp:1642637760\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,837 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,837 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:514e59a1-973c-4e92-ab14-df5ae4e95d8a,timestamp:1642637760\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,838 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,838 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,838 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,838 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,981 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,981 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8f076270-f867-46b7-9330-deedf9ad5137,timestamp:1642637760\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.79|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:0c7254ee-afee-46d9-8af6-f5d6d78cd927,timestamp:1642637760\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,436 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,634 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.74|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:dbe8a6c3-cf93-448a-b01a-6f22cd071f6f,timestamp:1642637760\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,635 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,635 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,635 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,636 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,636 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:ba94e425-70d3-4873-80e0-6ca0026d5bce,timestamp:1642637760\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,730 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,837 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,837 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.57|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:514e59a1-973c-4e92-ab14-df5ae4e95d8a,timestamp:1642637760\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,838 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,838 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,838 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,838 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,981 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,981 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:8f076270-f867-46b7-9330-deedf9ad5137,timestamp:1642637760\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,981 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,982 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,982 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:00,982 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,118 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,118 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.86|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:15ff170c-715f-490c-aba9-7bb89bb6f784,timestamp:1642637761\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,119 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,119 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,119 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,119 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:a129129b-f2f6-45d3-854b-178454d47062,timestamp:1642637761\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,380 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,380 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:a9786d77-916c-4c2f-a1db-d061f89dea19,timestamp:1642637761\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,381 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,381 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,381 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[34m2022-01-20 00:16:01,381 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,981 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,982 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,982 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:00,982 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,118 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,118 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.86|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:15ff170c-715f-490c-aba9-7bb89bb6f784,timestamp:1642637761\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,119 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 4\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,119 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,119 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,119 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.39|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:a129129b-f2f6-45d3-854b-178454d47062,timestamp:1642637761\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,262 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,380 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,380 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.37|#ModelName:model,Level:Model|#hostname:fdd7ad5e4df7,requestID:a9786d77-916c-4c2f-a1db-d061f89dea19,timestamp:1642637761\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,381 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:39562 \"POST /invocations HTTP/1.1\" 200 3\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,381 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,381 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n",
      "\u001b[35m2022-01-20 00:16:01,381 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:fdd7ad5e4df7,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "my_transformer = transformer.transform(\n",
    "    data=inference_inputs,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"application/x-image\",\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa2f9a",
   "metadata": {},
   "source": [
    "### Some useful methods to see the status of your batch inference jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a82fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest transform job \n",
      " pytorch-inference-2022-01-20-00-10-22-314\n"
     ]
    }
   ],
   "source": [
    "print(\"latest transform job \\n\", transformer.latest_transform_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251900e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2022, 1, 20, 0, 10, 22, 572000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'ModelName': 'pytorch-inference-2022-01-20-00-10-21-975',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '996',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Thu, 20 Jan 2022 00:16:40 GMT',\n",
      "                                      'x-amzn-requestid': 'cf36eb8f-a47c-4f5b-8e38-af7e04b95c69'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'cf36eb8f-a47c-4f5b-8e38-af7e04b95c69',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformEndTime': datetime.datetime(2022, 1, 20, 0, 16, 3, 517000, tzinfo=tzlocal()),\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
      "                                                    'S3Uri': 's3://sagemaker-us-west-2-328296961357/sagemaker/DEMO-pytorch-batch-inference-script/batch_transform/inference_images'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:328296961357:transform-job/pytorch-inference-2022-01-20-00-10-22-314',\n",
      " 'TransformJobName': 'pytorch-inference-2022-01-20-00-10-22-314',\n",
      " 'TransformJobStatus': 'Completed',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-west-2-328296961357/sagemaker/DEMO-pytorch-batch-inference-script/batch_transform/prediction_output'},\n",
      " 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.c5.xlarge'},\n",
      " 'TransformStartTime': datetime.datetime(2022, 1, 20, 0, 14, 10, 666000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "# look at the status of the transform job\n",
    "import boto3\n",
    "import pprint as pp\n",
    "\n",
    "sm_cli = boto3.client(\"sagemaker\")\n",
    "\n",
    "res = sm_cli.describe_transform_job(TransformJobName=transformer.latest_transform_job.name)\n",
    "\n",
    "pp.pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5489b3",
   "metadata": {},
   "source": [
    "### Download batch inference results from S3 to your local Jupyter Notebook machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "151442c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "sleep(5)\n",
    "sagemaker_session.download_data(path=local_output_path, bucket=bucket, key_prefix=s3_prediction_output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b7b1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.png.out   25.png.out\t40.png.out  56.png.out\t71.png.out  87.png.out\r\n",
      "10.png.out  26.png.out\t41.png.out  57.png.out\t72.png.out  88.png.out\r\n",
      "11.png.out  27.png.out\t42.png.out  58.png.out\t73.png.out  89.png.out\r\n",
      "12.png.out  28.png.out\t43.png.out  59.png.out\t74.png.out  8.png.out\r\n",
      "13.png.out  29.png.out\t44.png.out  5.png.out\t75.png.out  90.png.out\r\n",
      "14.png.out  2.png.out\t45.png.out  60.png.out\t76.png.out  91.png.out\r\n",
      "15.png.out  30.png.out\t46.png.out  61.png.out\t77.png.out  92.png.out\r\n",
      "16.png.out  31.png.out\t47.png.out  62.png.out\t78.png.out  93.png.out\r\n",
      "17.png.out  32.png.out\t48.png.out  63.png.out\t79.png.out  94.png.out\r\n",
      "18.png.out  33.png.out\t49.png.out  64.png.out\t7.png.out   95.png.out\r\n",
      "19.png.out  34.png.out\t4.png.out   65.png.out\t80.png.out  96.png.out\r\n",
      "1.png.out   35.png.out\t50.png.out  66.png.out\t81.png.out  97.png.out\r\n",
      "20.png.out  36.png.out\t51.png.out  67.png.out\t82.png.out  98.png.out\r\n",
      "21.png.out  37.png.out\t52.png.out  68.png.out\t83.png.out  99.png.out\r\n",
      "22.png.out  38.png.out\t53.png.out  69.png.out\t84.png.out  9.png.out\r\n",
      "23.png.out  39.png.out\t54.png.out  6.png.out\t85.png.out\r\n",
      "24.png.out  3.png.out\t55.png.out  70.png.out\t86.png.out\r\n"
     ]
    }
   ],
   "source": [
    "!ls {local_output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dcfdab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 ', '4 ', '0 ', '1 ', '4 ', '8 ', '0 ', '1 ', '9 ', '9 ', '2 ', '9 ', '7 ', '3 ', '0 ', '8 ']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x72 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display .png image files and corresponding predictions\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "N_files = 16\n",
    "\n",
    "im_list = []\n",
    "pred_list = []\n",
    "\n",
    "for i in range(N_files):\n",
    "    image_path=os.path.join(local_image_dir, f\"{i}.png\")\n",
    "    im_list.append(img.imread(image_path))\n",
    "    \n",
    "    pred_path = os.path.join(local_output_path, f\"{i}.png.out\")\n",
    "    with open(pred_path, \"r\") as F:\n",
    "        item=json.load(F)\n",
    "        pred_list.append( str(item[\"predictions\"])+ \" \")    \n",
    "    \n",
    "# plot the images\n",
    "fig, axs = plt.subplots(nrows=1, ncols=N_files, figsize=(16, 1))\n",
    "for k, splt in enumerate(axs):\n",
    "    splt.imshow(im_list[k])\n",
    "    \n",
    "print(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e626f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': 1}\n",
      "{'predictions': 6}\n",
      "{'predictions': 5}\n",
      "{'predictions': 0}\n",
      "{'predictions': 2}\n",
      "{'predictions': 7}\n",
      "{'predictions': 3}\n",
      "{'predictions': 7}\n",
      "{'predictions': 9}\n",
      "{'predictions': 5}\n",
      "{'predictions': 1}\n",
      "{'predictions': 3}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n",
      "{'predictions': 0}\n",
      "{'predictions': 0}\n",
      "{'predictions': 5}\n",
      "{'predictions': 8}\n",
      "{'predictions': 2}\n",
      "{'predictions': 9}\n",
      "{'predictions': 8}\n",
      "{'predictions': 3}\n",
      "{'predictions': 9}\n",
      "{'predictions': 3}\n",
      "{'predictions': 5}\n",
      "{'predictions': 2}\n",
      "{'predictions': 7}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 5}\n",
      "{'predictions': 1}\n",
      "{'predictions': 3}\n",
      "{'predictions': 4}\n",
      "{'predictions': 9}\n",
      "{'predictions': 4}\n",
      "{'predictions': 5}\n",
      "{'predictions': 6}\n",
      "{'predictions': 8}\n",
      "{'predictions': 4}\n",
      "{'predictions': 4}\n",
      "{'predictions': 1}\n",
      "{'predictions': 8}\n",
      "{'predictions': 9}\n",
      "{'predictions': 4}\n",
      "{'predictions': 7}\n",
      "{'predictions': 8}\n",
      "{'predictions': 6}\n",
      "{'predictions': 7}\n",
      "{'predictions': 0}\n",
      "{'predictions': 7}\n",
      "{'predictions': 6}\n",
      "{'predictions': 5}\n",
      "{'predictions': 2}\n",
      "{'predictions': 0}\n",
      "{'predictions': 8}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 3}\n",
      "{'predictions': 1}\n",
      "{'predictions': 9}\n",
      "{'predictions': 2}\n",
      "{'predictions': 3}\n",
      "{'predictions': 5}\n",
      "{'predictions': 2}\n",
      "{'predictions': 0}\n",
      "{'predictions': 5}\n",
      "{'predictions': 5}\n",
      "{'predictions': 8}\n",
      "{'predictions': 2}\n",
      "{'predictions': 2}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 9}\n",
      "{'predictions': 2}\n",
      "{'predictions': 3}\n",
      "{'predictions': 8}\n",
      "{'predictions': 2}\n",
      "{'predictions': 4}\n",
      "{'predictions': 2}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 3}\n",
      "{'predictions': 3}\n",
      "{'predictions': 6}\n",
      "{'predictions': 4}\n",
      "{'predictions': 5}\n",
      "{'predictions': 1}\n",
      "{'predictions': 8}\n",
      "{'predictions': 9}\n",
      "{'predictions': 1}\n",
      "{'predictions': 0}\n",
      "{'predictions': 1}\n",
      "{'predictions': 1}\n",
      "{'predictions': 3}\n",
      "{'predictions': 4}\n",
      "{'predictions': 0}\n",
      "{'predictions': 6}\n",
      "{'predictions': 0}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the output\n",
    "\n",
    "import json\n",
    "\n",
    "for f in os.listdir(local_output_path):\n",
    "    path = os.path.join(local_output_path, f)\n",
    "    with open(path, \"r\") as f:\n",
    "        pred = json.load(f)\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981e48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 333.854918,
   "end_time": "2021-06-03T00:15:43.072184",
   "environment_variables": {},
   "exception": true,
   "input_path": "pytorch-mnist-batch-transform.ipynb",
   "output_path": "/opt/ml/processing/output/pytorch-mnist-batch-transform-2021-06-03-00-06-06.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-03T00:10:09.217266",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01005530a5b1473b9f4a024b19c04c0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_968ed82ad8f0453e8f81a839df4428db",
       "placeholder": "",
       "style": "IPY_MODEL_e4f0965e53ee40adb1ae44da87428325",
       "value": "  0%"
      }
     },
     "0995f6633c0f4facabe6759837c606ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "1410dcfcd117434889e9594cdde4e1b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "18caaab41d6146c1824859691f6cb435": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d823500ff0dc4c2198b83cd231f8bffe",
       "placeholder": "",
       "style": "IPY_MODEL_7dab31892241494e8d27d38ca98e5aa6",
       "value": " 0/28881 [00:00&lt;?, ?it/s]"
      }
     },
     "19ef65b0ecae45bdbca066cea679878d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2ceacd43f28744eb9b7a12f8276b6016",
        "IPY_MODEL_e44ddce6c5704f0b9495ee662806f5f6",
        "IPY_MODEL_7717cc87ebcc4c0581ae32848b40982c"
       ],
       "layout": "IPY_MODEL_59d0678977a343abb8a02dc5c9699b89"
      }
     },
     "2126024805384bff9b0409b4dc91e60c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "216ba33f9f1b486ebac2a6fce0510246": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f94b5a0d68c541e894e325a0e2f899d2",
       "placeholder": "",
       "style": "IPY_MODEL_633cc1cdb94e43a6a07559483496c60d",
       "value": "  0%"
      }
     },
     "23445154eb524df985b5a755fcbddd32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_216ba33f9f1b486ebac2a6fce0510246",
        "IPY_MODEL_c4f4f4bfe979469c9bc59ab73bbf518f",
        "IPY_MODEL_fe83e178358040eaa07f6198ba693fc9"
       ],
       "layout": "IPY_MODEL_cf1f337300394948bce741af7bcd8b8c"
      }
     },
     "235ae38cf16e4aacb95c3d16d9749da3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c2474d5a8144bf8930fa5cc02c73ccf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5495428879544d6da73e2ed7e70f0c96",
        "IPY_MODEL_6e2a4641cd944d9a8196f4a836e90590",
        "IPY_MODEL_9179e5f467c8450a988b988d7da06090"
       ],
       "layout": "IPY_MODEL_596f8cbad0884ec79cf6ee757cc9f38a"
      }
     },
     "2ceacd43f28744eb9b7a12f8276b6016": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a540362f86774590851c1d0892bea723",
       "placeholder": "",
       "style": "IPY_MODEL_bb9ebd025f05499da7b847b8ef7a9ff5",
       "value": ""
      }
     },
     "495839f4239743669d9ee61cfbc33967": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4d62b9fde9104c8081b545c3933a077e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "51a28ca59cf9407ea0e02da868d79ebd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5495428879544d6da73e2ed7e70f0c96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_235ae38cf16e4aacb95c3d16d9749da3",
       "placeholder": "",
       "style": "IPY_MODEL_fe60ae53dd1646ca91018ba20934948b",
       "value": ""
      }
     },
     "596f8cbad0884ec79cf6ee757cc9f38a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59d0678977a343abb8a02dc5c9699b89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "633cc1cdb94e43a6a07559483496c60d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "63a57f663bfa4a1585c1ba36501b6b23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e2a4641cd944d9a8196f4a836e90590": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fb8c653eeeb24799bcc9279389fdb523",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b513a456776d40b496f035c64360db90",
       "value": 1
      }
     },
     "7717cc87ebcc4c0581ae32848b40982c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9b63360561b34257b171498e67902dda",
       "placeholder": "",
       "style": "IPY_MODEL_f86487d9a78940a394503b2bea77d756",
       "value": " 9920512/? [04:50&lt;00:00, 36552.15it/s]"
      }
     },
     "7bceed60fb344aa182dccc3dcf0ee886": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_01005530a5b1473b9f4a024b19c04c0e",
        "IPY_MODEL_e82a5227430443d98d29555fd77b2bd3",
        "IPY_MODEL_18caaab41d6146c1824859691f6cb435"
       ],
       "layout": "IPY_MODEL_63a57f663bfa4a1585c1ba36501b6b23"
      }
     },
     "7dab31892241494e8d27d38ca98e5aa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8b5b76e77cb14ecf95a310ba46ed86f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "9179e5f467c8450a988b988d7da06090": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_94ef992b73d44d829b863815da70111f",
       "placeholder": "",
       "style": "IPY_MODEL_1410dcfcd117434889e9594cdde4e1b0",
       "value": " 1654784/? [00:47&lt;00:00, 33514.08it/s]"
      }
     },
     "94ef992b73d44d829b863815da70111f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "968ed82ad8f0453e8f81a839df4428db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b63360561b34257b171498e67902dda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a540362f86774590851c1d0892bea723": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b513a456776d40b496f035c64360db90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bb9ebd025f05499da7b847b8ef7a9ff5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c0b88a223b374693b6b0c74db9ffe346": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "c4f4f4bfe979469c9bc59ab73bbf518f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8b5b76e77cb14ecf95a310ba46ed86f5",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_51a28ca59cf9407ea0e02da868d79ebd",
       "value": 0
      }
     },
     "cf1f337300394948bce741af7bcd8b8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d823500ff0dc4c2198b83cd231f8bffe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e44ddce6c5704f0b9495ee662806f5f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0995f6633c0f4facabe6759837c606ba",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4d62b9fde9104c8081b545c3933a077e",
       "value": 1
      }
     },
     "e4f0965e53ee40adb1ae44da87428325": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e82a5227430443d98d29555fd77b2bd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c0b88a223b374693b6b0c74db9ffe346",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_495839f4239743669d9ee61cfbc33967",
       "value": 0
      }
     },
     "eb4c77cfe2c54976aef8efc0e3207140": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f86487d9a78940a394503b2bea77d756": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f94b5a0d68c541e894e325a0e2f899d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb8c653eeeb24799bcc9279389fdb523": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "fe60ae53dd1646ca91018ba20934948b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fe83e178358040eaa07f6198ba693fc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2126024805384bff9b0409b4dc91e60c",
       "placeholder": "",
       "style": "IPY_MODEL_eb4c77cfe2c54976aef8efc0e3207140",
       "value": " 0/4542 [00:00&lt;?, ?it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
